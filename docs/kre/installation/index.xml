<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Konstellation â€“ Installation</title><link>https://konstellation-io.github.io/website/docs/kre/installation/</link><description>Recent content in Installation on Konstellation</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://konstellation-io.github.io/website/docs/kre/installation/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Helm basics</title><link>https://konstellation-io.github.io/website/docs/kre/installation/helm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://konstellation-io.github.io/website/docs/kre/installation/helm/</guid><description>
&lt;p>KRE can be installed on top of a Kubernetes cluster using the &lt;a href="https://helm.sh/">Helm&lt;/a> package manager.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;ul>
&lt;li>Helm v3 or later&lt;/li>
&lt;li>Kubernetes v1.15+&lt;/li>
&lt;/ul>
&lt;h2 id="install-the-chart">Install the chart&lt;/h2>
&lt;ol>
&lt;li>Add the Konstellation Helm repository:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm repo add konstellation-io https://charts.konstellation.io
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>Optionally, create a namespace to deploy all KRE components or skip this step using a created one:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl create namespace kre
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>Run the following command, providing a name for your KRE release (in this case &lt;code>kre&lt;/code>) and specifying the namespace:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm upgrade --install kre --namespace kre konstellation-io/kre
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="uninstall-the-chart">Uninstall the chart&lt;/h2>
&lt;p>To uninstall the &lt;code>kre&lt;/code> deployment, use the following command:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm uninstall kre
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command removes all the Kubernetes components associated with the chart and deletes the release.&lt;/p></description></item><item><title>Docs: Minikube</title><link>https://konstellation-io.github.io/website/docs/kre/installation/minikube/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://konstellation-io.github.io/website/docs/kre/installation/minikube/</guid><description/></item><item><title>Docs: GKE</title><link>https://konstellation-io.github.io/website/docs/kre/installation/gke/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://konstellation-io.github.io/website/docs/kre/installation/gke/</guid><description/></item><item><title>Docs: EKS</title><link>https://konstellation-io.github.io/website/docs/kre/installation/eks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://konstellation-io.github.io/website/docs/kre/installation/eks/</guid><description>
&lt;h1 id="eks-deployment">EKS deployment&lt;/h1>
&lt;p>The flavor of Kubernetes on AWS is called EKS (Elastic Kubernetes Service) which allow to deploy a cluster managed by Amazon. This means that Amazon will manage the lifecyle of the Master nodes of our cluster.&lt;/p>
&lt;p>Currently there are two ways of run loads on top of EKS, using EC2 instances as compute nodes that are added to to the cluster or using the Fargate mode, where AWS also manage these compute nodes. In this guide is just described the first one, adding our own compute nodes with EC2 instances.&lt;/p>
&lt;p>Deploy an EKS cluster is not the goal of this guide, only the detail some specific configuration needed to run KRE on top of it. It is recomend to use IaC (Infrastructure As Code) approach using Terraform to automate the creation of your cluster, &lt;a href="https://learn.hashicorp.com/tutorials/terraform/eks">here&lt;/a> you can find usefull resources about that. Also you can follow the instructions from the official &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html">AWS site&lt;/a>.&lt;/p>
&lt;p>The final EKS deployment should be something like the below diagram.&lt;/p>
&lt;div class="card rounded p-2 td-post-card mb-4 mt-4" style="max-width: 610px">
&lt;img class="card-img-top" src="https://konstellation-io.github.io/website/website/docs/kre/installation/eks/eks_diagram_hu810904b9cb0bf96ab0f9422ba192b8fc_30553_600x0_resize_catmullrom_2.png" width="600" height="512">
&lt;div class="card-body px-0 pt-2 pb-0">
&lt;p class="card-text">
&lt;/p>
&lt;/div>
&lt;/div>
&lt;h1 id="storage">Storage&lt;/h1>
&lt;p>An important amount of features of KRE are based on the use of shared storage with &lt;code>ReadWriteMany&lt;/code> volumes. Therefore is required to add a storageClass to Kubernetes that support this kind of volumes.&lt;/p>
&lt;p>In AWS there are a service called EFS (Elastic File System) that bring to us a network shared storage. As was mentioned before, the recomended way to create resources is using the approach of IaC, for EFS you can find examples of Terraform code &lt;a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/efs_mount_target">here&lt;/a>, or follow the manual steps from the &lt;a href="https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html">AWS site&lt;/a>.&lt;/p>
&lt;p>The common way to use this from Kubernetes is deploying what is called &lt;code>efs-provisioner&lt;/code> that create the interface between Kubernetes &lt;code>PersistentVolumeClaim&lt;/code> and EFS.&lt;/p>
&lt;p>In our experience we have had some issues with the &lt;code>efs-provisioner&lt;/code>, therefore instead of deploy an &lt;code>efs-provisioner&lt;/code> to support the creation of volumes on EFS we prefer to add a script to the &lt;code>UserData&lt;/code> of each EC2 instance to mount the shared EFS on a local mount point, for example on &lt;code>/mnt/efs/kre&lt;/code>, and create a &lt;code>HostPath&lt;/code> storageClass that will create all the volumes within this path. This way we can create &lt;code>ReadWriteMany&lt;/code> volumes that are accesible from all the nodes of our cluster. The &lt;code>UserData&lt;/code> script example is below, and is good practice to set it in the &lt;code>Launch Configuration&lt;/code> that manage the EC2 instance which are the compute nodes of our cluster.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic">#!/bin/bash
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#204a87">set&lt;/span> -o xtrace
/etc/eks/bootstrap.sh --apiserver-endpoint &lt;span style="color:#4e9a06">&amp;#39;https://xxxxxxxxxxx.gr7.us-east-1.eks.amazonaws.com&amp;#39;&lt;/span> --b64-cluster-ca &lt;span style="color:#4e9a06">&amp;#39;xxxxxxxxxxxxx&amp;#39;&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;kre&amp;#39;&lt;/span>
mkdir -p /mnt/efs/kre
yum install amazon-efs-utils -y
&lt;span style="color:#204a87">echo&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;fs-xxxxxxxx.efs.us-east-1.amazonaws.com:/ /mnt/efs/kre efs tls,_netdev&amp;#34;&lt;/span> &amp;gt;&amp;gt; /etc/fstab
mount -a -t efs defaults
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the next section is described how to install the &lt;code>hostPath&lt;/code> provisioner.&lt;/p>
&lt;p>Network shared storage can be a bottle neck of performance, so depend of your usecase you should use only for the pieces that require
&lt;code>ReadWriteMany&lt;/code> volume, for the rest of the components you can use the default storageClass that will create an EBS resource on AWS. In the &lt;a href="#helm-deployment">Helm deployment&lt;/a> section is detailed the best option for your usecase and which pieces can use which storageClass.&lt;/p>
&lt;h1 id="kubernetes-required-components">Kubernetes required components&lt;/h1>
&lt;p>Some additional components are required on Kubernetes to get a full featured KRE deployment running. We are going to describe how to install those.&lt;/p>
&lt;h2 id="ingress-controller">Ingress controller&lt;/h2>
&lt;p>The use of Ingress Controller in Kubernetes that are deployed on cloud providers is very common, due to the reduction of costs on
load balancers, also the ingress objects help with the automation of some task when publish service to outside of our cluster, and many more.&lt;/p>
&lt;p>There are multiple choices of Ingress Controller (NGINX, Traefik, HAProxy, Kong, &amp;hellip;), you can find a full list of those
in the &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">Kubernetes site&lt;/a>, and all of them have pros and cons, in this guide we are going to explain how to deploy NGINX Ingress Controller. It is posible to use KRE with other Ingress Controller than NGINX, but this is matained by the CNCF and the maturity of NGINX itself is quite important.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm upgrade --install &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --namespace kube-system &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --version 1.40.2 &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> nginx-ingress &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> stable/nginx-ingress
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="cert-manager">Cert manager&lt;/h2>
&lt;p>The access to the web admin interface of KRE and all the endpoints that are exposed to the end users required of a minimun level of security,
this is the reason why add a piece to automate the management of the lifecycle of all required certificates.&lt;/p>
&lt;p>Cert Manager allow to create certificates just with some configuration on the deployment process, and manage the lifecycle of those, updating those when expired without any human interaction. Moreover, with
the use of &lt;code>DNS01&lt;/code> challenge method can be created certificates for environment that are not exposed to Internet behind a firewall in a private network.&lt;/p>
&lt;p>In order to install Cert Manager we are going to use the official Helm chart. Below are the commands to deploy it within the Kubernetes namespace &lt;code>cert-manager&lt;/code>, be aware that this is just a convention, you can deploy it in the namespace where you feel more confortable.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl create namespace cert-manager --dry-run -o yaml &lt;span style="color:#000;font-weight:bold">|&lt;/span> kubectl apply -f -
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm upgrade --install &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --namespace cert-manager &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --version v0.15.0 &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> --set &lt;span style="color:#000">installCRDs&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">true&lt;/span> &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> cert-manager &lt;span style="color:#4e9a06">\
&lt;/span>&lt;span style="color:#4e9a06">&lt;/span> jetstack/cert-manager
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="storage-provisioner">Storage provisioner&lt;/h2>
&lt;p>In order to create the &lt;code>hostPath&lt;/code> provisioner just install the Helm chart as shown below.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm upgrade --install hostpath-provisioner --namespace kube-system rimusz/hostpath-provisioner
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="dns">DNS&lt;/h1>
&lt;p>All the access to KRE services require of hostnames, due to the use of Ingress object and certificates. In order to get a
deployment and management processes easier we recommend to delegate a subdomain to a &lt;code>Route53&lt;/code> DNS zone, and create a wildcard
entry pointing to the Load Balancer of the Ingress Controller.&lt;/p>
&lt;h1 id="helm-deployment">Helm deployment&lt;/h1></description></item><item><title>Docs: Customization</title><link>https://konstellation-io.github.io/website/docs/kre/installation/customization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://konstellation-io.github.io/website/docs/kre/installation/customization/</guid><description>
&lt;h2 id="values">Values&lt;/h2>
&lt;p>The following table lists configurable parameters, their descriptions, and their default values stored in values.yaml.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Param&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>prometheusOperator.enabled&lt;/td>
&lt;td>Prometheus will be installed by default if you prefer use your own prometheus&lt;/td>
&lt;td>false&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item></channel></rss>